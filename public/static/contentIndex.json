{"index":{"title":"Burger Math","links":["math/Tensors"],"tags":[],"content":"\nTopics:\nTensors and Diff-Geo"},"math/Tensors":{"title":"Tensors","links":["math/Vectors"],"tags":[],"content":"\nSub-Topics\nVector and Coordinate Bases"},"math/Vectors":{"title":"Vectors","links":[],"tags":[],"content":"\nWhy talk about vectors???\nGiven the complexity of some of the topics that will be covered in this guide, it may seem odd to start with what is likely the billionth vector review for most. While annoying for some, you can rest easy knowing this section is not intended to be a comprehensive lesson on linear-algebra, and in fact will seem blazingly quick for someone with little to no prior knowledge bout vector spaces (if you have no idea what a vector is, you might find this series helpful).\nInstead, the first part of this page (which serves as the boiler-plate review) serves two purposes:\n\n\n1.) Disambiguate notation that will be commonly used throughout this website (this includes any future projects)\n\n\n2.) Provide a smooth transition into the latter half of this page, which will most likely be new material for some.\n\n\nFrom the second half onward, it will be assumed that you at least know what a vector is and some basic facts about vector spaces and operations on vector spaces.\nIf you feel super confident in your knowledge and feel the first section would be a waste of time, click here.\nIf you want to go ahead with the quickest vector review of all time, then the first question we should ask ourselves is:\n\nWhat is a Vector?\nThe most concise answer is that a vector \\vec {u} is an element of a vector space \\textbf{V}. In order for a set \\textbf{V} to constitute a vector space, there is a list of requirements (called the vector axioms) that must be satisfied:\n\n\\begin{gathered}\n\\forall \\{\\vec{u},\\vec{v},\\vec{w}\\}\\in\\textbf{V},\n\\end{gathered}\n\n\n1.)\\quad\\vec{u}+\\vec{v}\\in\\textbf{V},\\quad a\\vec{u}\\in\\textbf{V}   |   (Closure under vector addition and scalar multiplication)\n\n\n2.)\\quad\\vec{u}+(\\vec{v}+\\vec{w})=(\\vec{u}+\\vec{v})+\\vec{w}   |   (associativity of addition)\n\n\n3.)\\quad\\vec{u}+\\vec{v}=\\vec{v}+\\vec{u}   |   (commutativity of addition)\n\n\n4.)\\quad\\exists!{\\vec{0}}\\in\\textbf{V} \\,s.t. \\quad\\vec{0}+\\vec{u}=\\vec{u}   |   (existence of additive identity)\n\n\n5.)\\quad\\exists!(−{\\vec{u}})\\in\\textbf{V} \\,s.t. \\quad(−\\vec{u})+\\vec{u}=\\vec{0}   |   (existence of additive inverse)\n\n\n6.)\\quad a(b\\vec{u})=(ab)\\vec{u}   |   (scalar multiplication is equivalent to Field multiplcation)\n\n\n7.)\\quad1\\vec{u}=\\vec{u}   |   (multiplication by the identity element returns the vector original vector)\n\n\n8.)\\quad(a+b)(\\vec{u}+\\vec{v})=(a+b)\\vec{u}+(a+b)\\vec{v}=a(\\vec{u}+\\vec{v})+b(\\vec{u}+\\vec{v})=a\\vec{u}+b\\vec{u}+a\\vec{v}+b\\vec{v}   |   (scalar multiplication distributes)\n\n\n(\\forall  means for all, \\exists! means there exists only one, and \\in means within)\nThis definition is rather dense and includes sets not commonly thought of as vector spaces (such as the set of nth degree polynomials or even \\{0\\}), however for the majority of this section we wont need to reference it and will tend to focus on what most people imagine when thinking of a vector space, Euclidean vector spaces .\n\nLinear Combinations and span\nThe vector axioms define the properties of scalar multiplcation and vector addition, but often we’ll seek to make use of both operations at once. This leads us to the more general concept of a linear combination.\nA linear combination of vectors is simply just a sum of vectors weighted by scalar coefficients. Given any indexable set of vectors from \\textbf{V} \\{\\vec{u}_1,...,\\vec{u}_n\\} we can compactly represent any linear combination of vectors within this set like:\n\\begin{gathered}\n\\displaystyle\\sum_{i=1}^{n}c_{i}\\vec{u}_i=c_1\\vec{u}_1+...+c_n\\vec{u}_n\n\\end{gathered}\nWhere each coefficient could be any arbitray scalar. Also take not that since \\textbf{V} is closed under both addition and multiplication, a linear combination of vectors is itself a vector. Because generality is usually rewarded in mathematics, it’s often more fruitful to consider the set of all possible linear combinations of a given set of vectors. Exploring this idea further brings us to the concept of span.\nFormally the span of a set of vectors S is a subset of a space \\textbf{V} over a  Field {\\textbf{F}}, which can be defined as:\n\\begin{gathered}\nspan(S)= \\left\\{\n\\sum_{i=1}^{n}c_{i}\\vec{u}_{i} \\,\\middle|\\, c_{i}\\in\\mathbf{F},\\vec{u}_i\\in S\n\\right\\}\n\\end{gathered}\nThe span of a set of vectors is special as far as subsets of \\textbf{V} go in that it can be demonstrated to have its own vector space strucutre. All axioms dealing with the properties of operations are automatically met as a subset of a \\textbf{V}, and the remaining two axioms (existence of additive inverse and identity) can be shown to be satisfied in the following ways:\nAdditive Inverse\n\\begin{gathered}\nlet \\,\\sum_{i=1}^nc_{i}\\vec{u}_{i}\\equiv\\vec{v}. \\\\ \\\\\\forall\\vec{v}\\in span(S),\\\\\\\\ -\\vec{v}=-\\left(\\sum_{i=1}^nc_{i}\\vec{u}_{i}\\right) =\\sum_{i=1}^n(-c_{i})\\vec{u}_{i}\\,,\\\\\\\\ \\sum_{i=1}^n(-c_{i})\\vec{u}_{i}\\in span(S)\n\\end{gathered}\nAdditive identity\n\\begin{gathered}\n\\vec{0}=\\sum_{i=1}^n\\vec{0}=\\sum_{i=1}^n0\\vec{u}_{i}\\, ,\\\\\\\\\\sum_{i=1}^{n}0\\vec{u}_{i}\\in span(S)\n\\end{gathered}\nThus given any set of vectors in \\textbf{V}, the span of the set is simultaneously a subset of \\textbf{V} and a   vector space of its own. All such subsets are referred to as subspaces and are generally assumed to be subsets of larger vector spaces (though all vectors spaces are technically subspaces of themselves)\n\nLinear Independence and Vector Bases\nFor any subspace \\textbf{W} of a vector space \\textbf{V}, there are infinitely many choices of spanning sets S \\,\\,s.t. \\,span(S)=\\textbf{W}.\nThis is because the addition of a linear combination of vectors already in S doesn’t change the span of S, but still results in a completely new spanning set. If there is no upper bound for size of spanning  sets, is there a lower bound?\n\nCoordinate Bases for Euclidian Vector Spaces"}}